{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Selecting-and-Training-Models\" data-toc-modified-id=\"Selecting-and-Training-Models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Selecting and Training Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-raw-data-to-processed-data-in-2-steps\" data-toc-modified-id=\"From-raw-data-to-processed-data-in-2-steps-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>From raw data to processed data in 2 steps</a></span></li><li><span><a href=\"#Selecting-and-Training-Models\" data-toc-modified-id=\"Selecting-and-Training-Models-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Selecting and Training Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean-Squared-Error\" data-toc-modified-id=\"Mean-Squared-Error-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Mean Squared Error</a></span></li></ul></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Model-Evaluation-using-Cross-Validation\" data-toc-modified-id=\"Model-Evaluation-using-Cross-Validation-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Model Evaluation using Cross Validation</a></span></li><li><span><a href=\"#Random-Forest-model\" data-toc-modified-id=\"Random-Forest-model-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Random Forest model</a></span></li><li><span><a href=\"#Support-Vector-Machine-Regressor\" data-toc-modified-id=\"Support-Vector-Machine-Regressor-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Support Vector Machine Regressor</a></span></li><li><span><a href=\"#Hyperparameter-Tuning-using-GridSearchCV\" data-toc-modified-id=\"Hyperparameter-Tuning-using-GridSearchCV-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Hyperparameter Tuning using GridSearchCV</a></span></li><li><span><a href=\"#Checking-Feature-importance\" data-toc-modified-id=\"Checking-Feature-importance-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Checking Feature importance</a></span></li><li><span><a href=\"#Evaluating-the-entire-system-on-Test-Data\" data-toc-modified-id=\"Evaluating-the-entire-system-on-Test-Data-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Evaluating the entire system on Test Data</a></span></li><li><span><a href=\"#Creating-a-function-to-cover-this-entire-flow\" data-toc-modified-id=\"Creating-a-function-to-cover-this-entire-flow-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Creating a function to cover this entire flow</a></span></li><li><span><a href=\"#Save-the-Model\" data-toc-modified-id=\"Save-the-Model-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Save the Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fuel Efficiency of Vehicles - Part 3\n",
    "## Selecting and Training Models\n",
    "\n",
    "1. Select and Train a few Algorithms(Linear Regression, Decision Tree, RandomForest)\n",
    "2. Evaluation using Mean Squared Error\n",
    "3. Model Evaluation using Cross Validation\n",
    "4. Hyperparameter Tuning using GridSearchCV\n",
    "5. Check Feature Importance\n",
    "6. Evaluate the Final System on test data\n",
    "7. Saving the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing a few general use case libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the .data file using pandas\n",
    "\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.data', names=cols, na_values = \"?\",\n",
    "                comment = '\\t',\n",
    "                sep= \" \",\n",
    "                skipinitialspace=True)\n",
    "\n",
    "df = df.drop(['Origin'], axis=1)\n",
    "data = df.copy()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"Cylinders\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year\n",
       "145          4          83.0        61.0  2003.0          19.0          74\n",
       "151          4          79.0        67.0  2000.0          16.0          74\n",
       "388          4         156.0        92.0  2585.0          14.5          82\n",
       "48           6         250.0        88.0  3139.0          14.5          71\n",
       "114          4          98.0        90.0  2265.0          15.5          73\n",
       "..         ...           ...         ...     ...           ...         ...\n",
       "147          4          90.0        75.0  2108.0          15.5          74\n",
       "156          8         400.0       170.0  4668.0          11.5          75\n",
       "395          4         135.0        84.0  2295.0          11.6          82\n",
       "14           4         113.0        95.0  2372.0          15.0          70\n",
       "362          6         146.0       120.0  2930.0          13.8          81\n",
       "\n",
       "[318 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##segregate the feature and target variable\n",
    "data = strat_train_set.drop(\"MPG\", axis=1)\n",
    "data_labels = strat_train_set[\"MPG\"].copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##preprocess the Origin column in data\n",
    "# def preprocess_origin_cols(df):\n",
    "#     df[\"Origin\"] = df[\"Origin\"].map({1: \"India\", 2: \"USA\", 3: \"Germany\"})\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating custom attribute adder class\n",
    "acc_ix, hpower_ix, cyl_ix = 4,2, 0\n",
    "\n",
    "class CustomAttrAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power=True): # no *args or **kargs\n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acc_ix] / X[:, hpower_ix]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]\n",
    "        \n",
    "        return np.c_[X, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_pipeline_transformer(data):\n",
    "    '''\n",
    "    Function to process numerical transformations\n",
    "    Argument:\n",
    "        data: original dataframe \n",
    "    Returns:\n",
    "        num_attrs: numerical dataframe\n",
    "        num_pipeline: numerical pipeline object\n",
    "        \n",
    "    '''\n",
    "    numerics = ['float64', 'int64']\n",
    "\n",
    "    num_attrs = data.select_dtypes(include=numerics)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attrs_adder', CustomAttrAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "    return num_attrs, num_pipeline\n",
    "\n",
    "\n",
    "def pipeline_transformer(data):\n",
    "    '''\n",
    "    Complete transformation pipeline for both\n",
    "    nuerical and categorical data.\n",
    "    \n",
    "    Argument:\n",
    "        data: original dataframe \n",
    "    Returns:\n",
    "        prepared_data: transformed data, ready to use\n",
    "    '''\n",
    "#     cat_attrs = [\"Origin\"]\n",
    "    num_attrs, num_pipeline = num_pipeline_transformer(data)\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, list(num_attrs)),\n",
    "#         (\"cat\", OneHotEncoder(), cat_attrs),\n",
    "        ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From raw data to processed data in 2 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85657842, -1.07804475, -1.15192977, ..., -0.54436373,\n",
       "         1.70952741,  1.29565517],\n",
       "       [-0.85657842, -1.1174582 , -0.9900351 , ..., -0.54436373,\n",
       "         0.79867454,  0.666186  ],\n",
       "       [-0.85657842, -0.3587492 , -0.31547399, ...,  1.63652025,\n",
       "        -0.21906787,  0.35145142],\n",
       "       ...,\n",
       "       [-0.85657842, -0.56566984, -0.53133355, ...,  1.63652025,\n",
       "        -0.46365334, -0.25703544],\n",
       "       [-0.85657842, -0.78244384, -0.23452666, ..., -1.63480572,\n",
       "        -0.21548258,  0.45636295],\n",
       "       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.36390976,\n",
       "        -0.75313354, -0.76061078]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##from raw data to processed data in 2 steps\n",
    "# preprocessed_df = preprocess_origin_cols(data)\n",
    "prepared_data = pipeline_transformer(data)\n",
    "prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n",
       "       -0.54436373,  1.70952741,  1.29565517])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and Training Models\n",
    "\n",
    "1. Linear Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest\n",
    "4. SVM regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of samples:  [27.84899392 27.78225885 26.47235545 12.21626047 22.37038288]\n"
     ]
    }
   ],
   "source": [
    "##testing the predictions with the \n",
    "sample_data = data.iloc[:5]\n",
    "sample_labels = data_labels.iloc[:5]\n",
    "\n",
    "sample_data_prepared = pipeline_transformer(sample_data)\n",
    "\n",
    "print(\"Prediction of samples: \", lin_reg.predict(sample_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Labels of samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Labels of samples: \", list(sample_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.013004922657614"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mpg_predictions = lin_reg.predict(prepared_data)\n",
    "lin_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_predictions = tree_reg.predict(prepared_data)\n",
    "tree_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But no model is perfect, this means that our model has overfit the data to a great extent.\n",
    "\n",
    "We won't be touching out test data until we finalize our model. So, how do we check for what's happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Cross Validation\n",
    "\n",
    "Scikit-Learnâ€™s K-fold cross-validation feature randomly splits the training set into `K` distinct subsets called folds, then it trains and evaluates the model K times, picking a different fold for evaluation every time and training on the other K-1 folds. \n",
    "\n",
    "The result is an array containing the K evaluation scores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, \n",
    "                         prepared_data, \n",
    "                         data_labels, \n",
    "                         scoring=\"neg_mean_squared_error\", \n",
    "                         cv = 10)\n",
    "tree_reg_rmse_scores = np.sqrt(-scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26984327, 3.03901711, 3.40307765, 3.4191556 , 2.24053565,\n",
       "       3.31106101, 3.42084602, 3.6054646 , 4.1944664 , 2.34121557])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.224468287592594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.55607199, 3.44040236, 3.84137434, 2.64287754, 2.44982472,\n",
       "       2.83954804, 3.35920836, 2.42913501, 3.59460835, 2.90480891])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, prepared_data, data_labels, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "lin_reg_rmse_scores = np.sqrt(-scores)\n",
    "lin_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.105785962225056"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5648040779637773"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(prepared_data, data_labels)\n",
    "forest_reg_cv_scores = cross_val_score(forest_reg,\n",
    "                                         prepared_data,\n",
    "                                         data_labels,\n",
    "                                         scoring='neg_mean_squared_error',\n",
    "                                         cv = 10)\n",
    "\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_cv_scores)\n",
    "forest_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.149018656476251"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='linear')\n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "svm_cv_scores = cross_val_score(svm_reg, prepared_data, data_labels,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                cv = 10)\n",
    "svm_rmse_scores = np.sqrt(-svm_cv_scores)\n",
    "svm_rmse_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True,\n",
    "                           cv=10,\n",
    "                          )\n",
    "\n",
    "grid_search.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4785930890278407 {'max_features': 2, 'n_estimators': 3}\n",
      "2.942002823744286 {'max_features': 2, 'n_estimators': 10}\n",
      "2.842846265866842 {'max_features': 2, 'n_estimators': 30}\n",
      "3.2435712022807874 {'max_features': 4, 'n_estimators': 3}\n",
      "2.9193407376909493 {'max_features': 4, 'n_estimators': 10}\n",
      "2.6737646839476072 {'max_features': 4, 'n_estimators': 30}\n",
      "3.0216037393586364 {'max_features': 6, 'n_estimators': 3}\n",
      "2.6649749060732257 {'max_features': 6, 'n_estimators': 10}\n",
      "2.7047530682016494 {'max_features': 6, 'n_estimators': 30}\n",
      "2.931230937225464 {'max_features': 8, 'n_estimators': 3}\n",
      "2.7137915629571516 {'max_features': 8, 'n_estimators': 10}\n",
      "2.7009702182452275 {'max_features': 8, 'n_estimators': 30}\n",
      "3.4816002048711936 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "3.075292683749923 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.322726268688233 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "2.8179001866094455 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3.2527830825706876 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "2.741324830186451 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "##printing all the parameters along with their scores\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06455734, 0.20620092, 0.17239425, 0.35479719, 0.01438541,\n",
       "       0.12405189, 0.04484678, 0.01876621])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importances \n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.04484678123108904),\n",
       " ('acc_on_cyl', 0.018766212170111974),\n",
       " ('Weight', 0.3547971901963191),\n",
       " ('Model Year', 0.12405189173889639),\n",
       " ('Horsepower', 0.17239425106792017),\n",
       " ('Displacement', 0.2062009235022128),\n",
       " ('Cylinders', 0.06455734374343307),\n",
       " ('Acceleration', 0.014385406350017558)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attrs = [\"acc_on_power\", \"acc_on_cyl\"]\n",
    "numerics = ['float64', 'int64']\n",
    "num_attrs = list(data.select_dtypes(include=numerics))\n",
    "\n",
    "attrs = num_attrs + extra_attrs\n",
    "sorted(zip(attrs, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the entire system on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"MPG\", axis=1)\n",
    "y_test = strat_test_set[\"MPG\"].copy()\n",
    "\n",
    "# X_test_preprocessed = preprocess_origin_cols(X_test)\n",
    "X_test_prepared = pipeline_transformer(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.112326099559621"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to cover this entire flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mpg(config, model):\n",
    "    \n",
    "    if type(config) == dict:\n",
    "        df = pd.DataFrame(config)\n",
    "    else:\n",
    "        df = config\n",
    "    \n",
    "#     preproc_df = preprocess_origin_cols(df)\n",
    "    prepared_df = pipeline_transformer(df)\n",
    "    y_pred = model.predict(prepared_df)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.34, 16.65, 18.5 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking it on a random sample\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78]\n",
    "}\n",
    "\n",
    "predict_mpg(vehicle_config, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the model\n",
    "with open(\"model.bin\", 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.83333333, 18.50666667, 20.56333333])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading the model from the saved file\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "predict_mpg(vehicle_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
